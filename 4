import math
import pandas as pd

# Load the dataset (adjust the file path if needed)
file_path = '/content/Lipstick.csv'
data = pd.read_csv(file_path)

# Function to calculate entropy
def calculate_entropy(data, target_column):
    values = data[target_column].value_counts(normalize=True)
    entropy = -sum(values * values.apply(lambda p: math.log2(p) if p > 0 else 0))
    return entropy

# Function to calculate weighted entropy for a given attribute
def calculate_weighted_entropy(data, attribute, target_column):
    weighted_entropy = 0
    total_count = len(data)
    for value in data[attribute].unique():
        subset = data[data[attribute] == value]
        subset_entropy = calculate_entropy(subset, target_column)
        weighted_entropy += (len(subset) / total_count) * subset_entropy
    return weighted_entropy

# Function to calculate information gain
def calculate_information_gain(data, attribute, target_column):
    entropy_target = calculate_entropy(data, target_column)
    weighted_entropy = calculate_weighted_entropy(data, attribute, target_column)
    info_gain = entropy_target - weighted_entropy
    return info_gain

# Target column
target_column = 'Buys'

# Calculate entropy of the target
entropy_buys = calculate_entropy(data, target_column)
print(f"Entropy of {target_column}: {entropy_buys}")

# Calculate information gain for each attribute
attributes = [col for col in data.columns if col not in ['Id', target_column]]
info_gains = {}

for attribute in attributes:
    info_gain = calculate_information_gain(data, attribute, target_column)
    info_gains[attribute] = info_gain
    print(f"Information Gain for {attribute}: {info_gain}")

# Determine the root node
root_node = max(info_gains, key=info_gains.get)
print(f"\nRoot Node: {root_node}")
